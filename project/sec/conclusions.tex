\section{Conclusion}
This study presented an extended version of the TSception model, incorporating an LSTM layer to enhance the capability of capturing complex sequential temporal dynamics and spatial asymmetries from EEG data. The extended model, TSception-2, was rigorously evaluated against the original TSception model using the DEAP dataset for emotion analysis. The results were promising, showing that the inclusion of LSTM led to a notable improvement in both accuracy and F1 scores for the dimensions of arousal and valence.

The convergence analysis indicated that LSTM contributes to a faster and more robust learning process, as evidenced by steeper declines in loss during the initial training epochs and lesser fluctuations in validation loss, suggesting improved generalizability. The TSception-2 model achieved an accuracy improvement of 1.77\% for arousal and 0.5\% for valence, while F1 scores saw an enhancement of 2.2\% for arousal and 1.9\% for valence compared to the original TSception model.

These findings underscore the efficacy of LSTM layers in handling EEG signal variability and the non-stationary nature of emotional states. The comprehensive evaluation and interpretability analysis shed light on the network's functionality and highlighted the potential of deep learning methods in advancing BCI technologies for emotion recognition. Future work could explore the integration of other modalities and the application of the model in real-time systems, paving the way for innovative solutions in healthcare, gaming, and assistive technologies.
