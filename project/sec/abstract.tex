\begin{abstract}
    In our study, we have proposed a model called Tsception which is used for emotion recognition. The data consists of EEG signals captured from an experimental set up. The proposed model of Tsception has a CNN architecture with several convolutional blocks. It consists of Temporal and spatial convolutional layers which are respectively used to capture temporal and spatial dependencies.The dynamic temporal layer uses varying sized kernels corresponding to different sampling rates to capture the finer spectra ot temporal patterns. The spatial assymmetric layer learns discriminative patterns between left and right hemispheres. The fusion layer fuses outputs from both convolutional layers and gives a higher level representation of the data. The concatenated output is passed to fully connected layer for training. The study evaluates emotion recognition across two dimensions arousal and valence. The data were collected from 32 subjects to evaluate the model performance. The proposed model is seen to outperform various state of the art methods like SVM, EEGNet, LSTM etc.
\end{abstract}